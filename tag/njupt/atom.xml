<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://mashiro.zone</id>
    <title>雨落新痕のblog • Posts by &#34;njupt&#34; tag</title>
    <link href="https://mashiro.zone" />
    <updated>2020-10-02T08:16:13.000Z</updated>
    <category term="git" />
    <category term="CTF" />
    <category term="NJUPT" />
    <category term="Github" />
    <category term="Hexo" />
    <category term="博客搭建" />
    <category term="test" />
    <category term="不好，是大佬" />
    <category term="notes" />
    <category term="change" />
    <category term="feeling" />
    <category term="misc" />
    <category term="web" />
    <category term="note" />
    <category term="信安数基" />
    <category term="plan" />
    <category term="python" />
    <entry>
        <id>https://mashiro.zone/B19031125/</id>
        <title>0xGamewriteup</title>
        <link rel="alternate" href="https://mashiro.zone/B19031125/"/>
        <content type="html">&lt;p&gt;&lt;a id=&#34;more&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;萌萌萌新的writeup&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#萌萌萌新的writeup&#34;&gt;#&lt;/a&gt; 萌萌萌新的 writeup&lt;/h2&gt;
&lt;h3 id=&#34;web&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#web&#34;&gt;#&lt;/a&gt; web&lt;/h3&gt;
&lt;h4 id=&#34;1-view_source&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-view_source&#34;&gt;#&lt;/a&gt; 1 view_source&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;在谷歌浏览器中直接右键点击查看源代码，可以在一只牛牛的注释代码上面发现 flag&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-robots协议&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-robots协议&#34;&gt;#&lt;/a&gt; 2 robots 协议&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Robots 协议是 Web 站点和搜索引擎爬虫交互的一种方式，Robots.txt 是存放在站点根目录下的一个纯文本文件。该文件可以指定搜索引擎爬虫只抓取指定的内容，或者是禁止搜索引擎爬虫抓取网站的部分或全部内容。当一个搜索引擎爬虫访问一个站点时，它会首先检查该站点根目录下是否存在 robots.txt，如果存在，搜索引擎爬虫就会按照该文件中的内容来确定访问的范围；如果该文件不存在，那么搜索引擎爬虫就沿着链接抓取。另外，robots.txt 必须放置在一个站点的根目录下，而且文件名必须全部小写。如果搜索引擎爬虫要访问的网站地址是 http：&lt;a href=&#34;//www.w3.org/%EF%BC%8C%E9%82%A3%E4%B9%88robots.txt%E6%96%87%E4%BB%B6%E5%BF%85%E9%A1%BB%E8%83%BD%E5%A4%9F%E9%80%9A%E8%BF%87http%EF%BC%9A//www.w3.org/robots.txt%E6%89%93%E5%BC%80%E5%B9%B6%E7%9C%8B%E5%88%B0%E9%87%8C%E9%9D%A2%E7%9A%84%E5%86%85%E5%AE%B9%E3%80%82&#34;&gt;//www.w3.org/，那么 robots.txt 文件必须能够通过 http：//www.w3.org/robots.txt 打开并看到里面的内容。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;在网址的后面输入 robots.txt，就可以发现网站不允许被爬取的是 flaaaggg.php 这个页面，接着在网址后面输入 flaaaggg.php 就得到了 flag。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;3-getpost&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-getpost&#34;&gt;#&lt;/a&gt; 3 get&amp;amp;post&lt;/h4&gt;
&lt;p&gt;所需工具：火狐浏览器，Hackbar Quantum (hackbar 好像不能用了)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;GET 提交，请求的数据会附在 URL 之后（就是把数据放置在 HTTP 协中），以？分割 URL 和传输数据，多个参数用 &amp;amp; 连接例如如果数据是英文字母字，原样发送，如果是空格，转换为 +，如果是中文 / 其他字符，则直接把字符串用 BASE64 加密，得出如： % E4% BD% A0% E5% A5% BD，其中％XX 中的 XX 为该符号以 16 进制表示的 ASCII。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;POST 提交：把提交的数据放置在是 HTTP 包的包体中。上文示例中红色字体标明的就是实际的传输数据因此，GET 提交的数据会在地址栏中显示出来，而 POST 提交，地址栏不会改变&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;2、传输数据的大小：首先声明：HTTP 协议没有对传输的数据大小进行限制，HTTP 协议规范也没有对 URL 长度进行限制。而在实际开发中存在的限制主要有：GET: 特定浏览器和服务器对 URL 长度有限制，例如 IE 对 URL 长度的限制是 2083 字节 (2K+35)。对于其他浏览器，如 Netscape、FireFox 等，理论上没有长度限制，其限制取决于操作系 统的支持。因此对于 GET 提交时，传输数据就会受到 URL 长度的 限制。POST: 由于不是通过 URL 传值，理论上数据不受 限。但实际各个 WEB 服务器会规定对 post 提交数据大小进行限制，Apache、IIS6 都有各自的配置。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;做题思路：了解基本的 php 语法后可以知道只要分别让变量 0xGame 以 get 方式等于 acd666tql，X1cT34m 以 post 方式等于 acd666tql, 就可以得到 flag。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;4 wh1sper&#39;s_secret_garden&lt;br /&gt;
 工具：火狐浏览器，burpsuite&lt;br /&gt;
 参考 &lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tyX0JpZy9hcnRpY2xlL2RldGFpbHMvNzM2OTQzNTY/dXRtX21lZGl1bT1kaXN0cmlidXRlLnBjX3JlbGV2YW50Lm5vbmUtdGFzay1ibG9nLUJsb2dDb21tZW5kRnJvbUJhaWR1LTUuY2hhbm5lbF9wYXJhbSZhbXA7ZGVwdGhfMS11dG1fc291cmNlPWRpc3RyaWJ1dGUucGNfcmVsZXZhbnQubm9uZS10YXNrLWJsb2ctQmxvZ0NvbW1lbmRGcm9tQmFpZHUtNS5jaGFubmVsX3BhcmFt&#34;&gt;header 题总结&lt;/span&gt;&lt;br /&gt;
学会使用 burpsuite 之后一步步抓包依据提示修改即可。&lt;/p&gt;
&lt;h3 id=&#34;misc&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#misc&#34;&gt;#&lt;/a&gt; Misc&lt;/h3&gt;
&lt;h4 id=&#34;1-签到&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-签到&#34;&gt;#&lt;/a&gt; 1 签到&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;在 rules 页面发现 flag，copy 一下就可。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-easybase&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-easybase&#34;&gt;#&lt;/a&gt; 2 easybase&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;先运用 base64 在线解码工具解码，然后发现是 16 进制再转化为 ASCII 码即可。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;3-qr_repair&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-qr_repair&#34;&gt;#&lt;/a&gt; 3 QR_repair&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;打开发现是 GIF 格式的二维码，可以用分帧工具分解得到 4 张图片，然后在 ps 里把有二维码的两张图片拼接在一起，最后找到 qr 码的定位图，调整到合适大小，组合在一起，最后扫码得到 flag。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9kZXYuZ2FtZXJlcy5jb20vUHJvZ3JhbS9WaXN1YWwvT3RoZXIlMjAvR0lGRG9jLmh0bQ==&#34;&gt;gif 格式&lt;/span&gt;&lt;br /&gt;
&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMDUzOTM5OA==&#34;&gt;隐写书介绍&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;二周目&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#二周目&#34;&gt;#&lt;/a&gt; 二周目&lt;/h3&gt;
&lt;p&gt;just_login&lt;/p&gt;
&lt;p&gt;检查网页源代码，没有啥问题，尝试用一下万能密码&lt;/p&gt;
&lt;p&gt;一：username:1&#39;=&#39;0  password:1&#39;=&#39;0&lt;/p&gt;
&lt;p&gt;二：username:what&#39;=&#39;  password:what&#39;=&#39;&lt;/p&gt;
&lt;p&gt;三：username:admin&#39;=&#39;  password:admin&#39;=&#39;&lt;/p&gt;
&lt;h3 id=&#34;differentpic&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#differentpic&#34;&gt;#&lt;/a&gt; differentPic&lt;/h3&gt;
&lt;p&gt;用 Stegsolve 打开图片，选择对比功能，在异或时可以看到一张二维码，&lt;/p&gt;
&lt;h3 id=&#34;extract&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#extract&#34;&gt;#&lt;/a&gt; extract&lt;/h3&gt;
&lt;p&gt;感觉是最低有效位 LSB 隐写，但没做出来&lt;/p&gt;
</content>
        <category term="CTF" />
        <category term="NJUPT" />
        <updated>2020-10-02T08:16:13.000Z</updated>
    </entry>
</feed>
